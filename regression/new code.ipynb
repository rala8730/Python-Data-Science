{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 11.95\n",
      "Variance score: 0.91\n",
      "Mean squared error2: 113.26\n",
      "Variance score2: 0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rasmi/Library/Applications/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:466: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Perceptron\n",
    "import pandas\n",
    "import numpy\n",
    "import matplotlib as plt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import linear_model, feature_extraction\n",
    "def categorical_features(row):\n",
    "    d = {}\n",
    "    d[\"STATE\"] = row[1][\"STATE\"]\n",
    "    return d\n",
    "\n",
    "def last_poll(full_data):\n",
    "    \"\"\"\n",
    "    Create feature from last poll in each state\n",
    "    \"\"\"\n",
    "    \n",
    "    # Only care about republicans\n",
    "    repub = full_data[full_data[\"PARTY\"] == \"Rep\"]\n",
    "\n",
    "    # Sort by date\n",
    "    chron = repub.sort_values(by=\"DATE\", ascending=True)\n",
    "\n",
    "    # Only keep the last one\n",
    "    dedupe = chron.drop_duplicates(subset=\"STATE\", keep=\"last\")\n",
    "\n",
    "    # Remove national polls\n",
    "    return dedupe[dedupe[\"STATE\"] != \"US\"]\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # Read in the X data\n",
    "    all_data = pandas.read_csv(\"data.csv\")\n",
    "\n",
    "    # Remove non-states\n",
    "    all_data = all_data[pandas.notnull(all_data[\"STATE\"])]\n",
    "\n",
    "    # split between testing and training\n",
    "    train_x = last_poll(all_data[all_data[\"TOPIC\"] == '2012-president'])\n",
    "    train_x.set_index(\"STATE\")\n",
    "    \n",
    "    test_x = last_poll(all_data[all_data[\"TOPIC\"] == '2016-president'])\n",
    "    test_x.set_index(\"STATE\")\n",
    "    \n",
    "    # Read in the Y data\n",
    "    y_data = pandas.read_csv(\"../data/2012_pres.csv\", sep=';')\n",
    "    y_data = y_data[y_data[\"PARTY\"] == \"R\"]\n",
    "    y_data = y_data[pandas.notnull(y_data[\"GENERAL %\"])]\n",
    "    y_data[\"GENERAL %\"] = [float(x.replace(\",\", \".\").replace(\"%\", \"\"))\n",
    "                           for x in y_data[\"GENERAL %\"]]\n",
    "    y_data[\"STATE\"] = y_data[\"STATE ABBREVIATION\"]\n",
    "    y_data.set_index(\"STATE\")\n",
    "\n",
    "    backup = train_x\n",
    "    train_x = y_data.merge(train_x, on=\"STATE\",how='left')\n",
    "    \n",
    "    # make sure we have all states in the test data\n",
    "    for ii in set(y_data.STATE) - set(test_x.STATE):\n",
    "        new_row = pandas.DataFrame([{\"STATE\": ii}])\n",
    "        test_x = test_x.append(new_row)\n",
    "\n",
    "    # format the data for regression\n",
    "    train_x = pandas.concat([train_x.STATE.astype(str).str.get_dummies(),\n",
    "                             train_x], axis=1)\n",
    "    test_x = pandas.concat([test_x.STATE.astype(str).str.get_dummies(),\n",
    "                             test_x], axis=1)\n",
    "        \n",
    "    # handle missing data\n",
    "    for dd in train_x, test_x:                \n",
    "        dd[\"NOPOLL\"] = pandas.isnull(dd[\"VALUE\"])\n",
    "        dd[\"VALUE\"] = dd[\"VALUE\"].fillna(0.0)\n",
    "        dd[\"NOMOE\"] = pandas.isnull(dd[\"MOE\"])\n",
    "        dd[\"MOE\"] = dd[\"MOE\"].fillna(0.0)\n",
    "        \n",
    "    # create feature list\n",
    "    features = list(y_data.STATE)\n",
    "    features.append(\"VALUE\")\n",
    "    features.append(\"NOPOLL\")\n",
    "    features.append(\"MOE\")\n",
    "    features.append(\"NOMOE\")\n",
    "    \n",
    "    features_rep = list(y_data.PARTY)# from y data \n",
    "    features_rep = [ord(i) for i in features_rep]# changing R into ascii value \n",
    "    features_obs = list(all_data.OBS)#from  csv all_data since its not in y data \n",
    "    features_val = list(all_data.VALUE)# adding value as features\n",
    "    features_moe = list(all_data.MOE)\n",
    "    \n",
    "    feature_matrix=[] #creating empty matrix\n",
    "    for i in range(len(features_rep)):\n",
    "        feature_matrix.append([features_rep[i],features_obs[i],features_val[i],features_moe[i]])# appending to list R and OBS\n",
    "    features_matrix=numpy.array(feature_matrix)#returning an array with value of R and OBs \n",
    "        \n",
    "    \n",
    "    feature_matrix1=[] #creating empty matrix\n",
    "    for i in range(len(features_rep)):\n",
    "        feature_matrix1.append([features_rep[i],features_obs[i],features_val[i],features_moe[i]])# appending to list R and OBS\n",
    "    features_matrix1=numpy.array(feature_matrix1)#returning an array with value of R and OBs \n",
    "     \n",
    "    \n",
    "    # fit the regression\n",
    "    #mod = linear_model.LinearRegression()\n",
    "    #mod = linear_model.Ridge(alpha=.667)\n",
    "    #mod = linear_model.BayesianRidge()\n",
    "    #mod.fit(train_x[features], train_x[\"GENERAL %\"])\n",
    "\n",
    "    \n",
    "    #pipelining\n",
    "    mod=make_pipeline(PolynomialFeatures(degree=6),linear_model.LinearRegression())# making a model for polynomial regression \n",
    "    mod.fit(feature_matrix, train_x[\"GENERAL %\"])# passing matris with feature\n",
    "    \n",
    "    #modd=make_pipeline(PolynomialFeatures(degree=4),linear_model.BayesianRidge())# making a model for polynomial regression \n",
    "    #modd.fit(feature_matrix1, train_x[\"GENERAL %\"])# passing matris with feature\n",
    "    \n",
    "    modd=make_pipeline(PolynomialFeatures(degree=4),linear_model.Lasso())# making a model for polynomial regression \n",
    "    modd.fit(feature_matrix1, train_x[\"GENERAL %\"])# passing matris with feature\n",
    "    \n",
    "    \n",
    "    # Write out the model\n",
    "    #with open(\"model.txt\", 'w') as out:\n",
    "        #out.write(\"BIAS\\t%f\\n\" % mod.intercept_)\n",
    "        #for jj, kk in zip(features, mod.coef_):\n",
    "            #out.write(\"%s\\t%f\\n\" % (jj, kk))\n",
    "    \n",
    "    # Write the predictions\n",
    "    pred_test = mod.predict(features_matrix)\n",
    "    with open(\"pred.txt\", 'w') as out:\n",
    "        for ss, vv in sorted(zip(list(test_x.STATE), pred_test)):\n",
    "            out.write(\"%s\\t%f\\n\" % (ss, vv))\n",
    "\n",
    "    # Write the predictions\n",
    "    pred_test = modd.predict(feature_matrix1)\n",
    "    with open(\"pred.txt\", 'w') as out:\n",
    "        for ss, vv in sorted(zip(list(test_x.STATE), pred_test)):\n",
    "            out.write(\"%s\\t%f\\n\" % (ss, vv))\n",
    "            \n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % numpy.mean((mod.predict(features_matrix) - train_x[\"GENERAL %\"]) ** 2))\n",
    "#test data - train data\n",
    "#(prediction - observed)^2\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % mod.score(features_matrix,train_x[\"GENERAL %\"]))\n",
    "\n",
    "print(\"Mean squared error2: %.2f\"\n",
    "      % numpy.mean((modd.predict(features_matrix1) - train_x[\"GENERAL %\"]) ** 2))\n",
    "#test data - train data\n",
    "#(prediction - observed)^2\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score2: %.2f' % modd.score(features_matrix1,train_x[\"GENERAL %\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
